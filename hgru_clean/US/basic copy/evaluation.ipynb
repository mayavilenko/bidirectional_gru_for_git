{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import os\n",
    "from pipeline_config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeds for reproducability:\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(2)\n",
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/mvilenko/Library/CloudStorage/OneDrive-PayPal/hgru_clean/US/basic copy/predictions_dict.pickle', 'rb') as f:\n",
    "    prediction_dic = pickle.load(f)\n",
    "\n",
    "with open('/Users/mvilenko/Library/CloudStorage/OneDrive-PayPal/hgru_clean/pickle_files/bi_directional_us_dataset_dict.pickle', 'rb') as f:\n",
    "    raw_dataset_dict = pickle.load(f)\n",
    "    \n",
    "with open(category_id_to_category_name_path, 'rb') as f:\n",
    "    category_id_to_name_dict = pickle.load(f)\n",
    "    \n",
    "with open(categories_per_indent_path, 'rb') as f:\n",
    "    categories_per_indent_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dataframe(raw_dataset_dict: dict):\n",
    "    test_dict = {}\n",
    "    for key in raw_dataset_dict.keys():\n",
    "    #for key in ['All items']:\n",
    "        df = raw_dataset_dict[key][['Category', 'Date', 'Year', 'Indent', 'Inflation t+1']]\n",
    "        df.dropna(inplace=True)\n",
    "        df.rename(columns={'Inflation t+1': 'Actual'}, inplace=True)\n",
    "        target_df = df[df['Year'] > Year]\n",
    "        test_dict[key] = target_df\n",
    "    return test_dict\n",
    "\n",
    "test_dict = create_test_dataframe(raw_dataset_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_with_predictions(prediction_dic: dict, dict_of_categories_df:dict) -> dict:\n",
    "    all_data_dict = {}\n",
    "    for key in list(prediction_dic.keys()):\n",
    "        predictions = prediction_dic[key]\n",
    "        prediction_df =  pd.DataFrame(predictions.flatten().detach().numpy())\n",
    "        prediction_df.rename(columns = {0: 'Prediction'}, inplace=True)\n",
    "        dict_of_categories_df[key] = dict_of_categories_df[key].reset_index(drop=True)\n",
    "        all_data_dict[key] = pd.concat([dict_of_categories_df[key], prediction_df], axis=1)\n",
    "    return all_data_dict\n",
    "\n",
    "all_data_test_dict=get_df_with_predictions(prediction_dic, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "all_categories = list(all_data_test_dict.keys())\n",
    "len(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_rmse(all_data_test_dict):\n",
    "    mse_lst = []\n",
    "    for key in all_categories:\n",
    "        df_predictions = all_data_test_dict[key]\n",
    "        y_pred = df_predictions['Prediction'].values\n",
    "        y_actual = df_predictions['Actual'].values\n",
    "        mse = mean_squared_error(y_pred, y_actual)\n",
    "        mse_lst.append(mse)\n",
    "    \n",
    "    rmse_list = list(map(np.sqrt,mse_lst))\n",
    "    avg_rmse = np.mean(rmse_list)\n",
    "    rmse_std = np.std(rmse_list)\n",
    "    \n",
    "    print(f'RMSE:  {avg_rmse}')\n",
    "    print(f'MSE std:  {rmse_std}')\n",
    "    print(f'interval: {[avg_rmse-rmse_std, avg_rmse+rmse_std]}')\n",
    "\n",
    "    return avg_rmse,rmse_std\n",
    "\n",
    "avg_rmse(all_data_test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Headline RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = all_data_test_dict['All items']\n",
    "y_pred = df_predictions['Prediction'].values\n",
    "y_actual = df_predictions['Actual'].values\n",
    "mse = mean_squared_error(y_pred, y_actual)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "print(f'rmse: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_corr(all_data_test_dict):\n",
    "    corr_dict = {}\n",
    "    for key in all_categories:\n",
    "        df_predictions = all_data_test_dict[key]\n",
    "        y_pred = df_predictions['Prediction'].values\n",
    "        y_actual = df_predictions['Actual'].values\n",
    "        corr = stats.pearsonr(y_pred,y_actual)[0]\n",
    "        corr_dict[key] =  corr\n",
    "    \n",
    "    total_corr = sum(corr_dict.values())\n",
    "    \n",
    "    num_high_corr = 0\n",
    "    for category in corr_dict:\n",
    "        if corr_dict[category] >= 0.5:\n",
    "            num_high_corr +=1\n",
    "    \n",
    "    print(f'Number of categories with High Correlation: {num_high_corr}')\n",
    "    \n",
    "    return total_corr\n",
    "\n",
    "total_corr(all_data_test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average R2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_r_squared(all_data_test_dict):\n",
    "    r_squared_lst = []\n",
    "\n",
    "    for key in all_categories:\n",
    "        #print(f'category: {key}')\n",
    "        df_predictions = all_data_test_dict[key]\n",
    "        y_pred = df_predictions['Prediction'].values\n",
    "        y_actual = df_predictions['Actual'].values\n",
    "        r2 = r2_score(y_actual, y_pred)\n",
    "        r_squared_lst.append(r2)\n",
    "\n",
    "        if key =='All items':\n",
    "            headline_r2 = r2\n",
    "    \n",
    "    avg_r2_score = np.mean(r_squared_lst)\n",
    "    r2_std = np.std(r_squared_lst)\n",
    "    \n",
    "    print(f'Average R Squared:  {avg_r2_score}')\n",
    "    print(f'R Squared std:  {r2_std}')\n",
    "    print('--------------------------------------------------------')\n",
    "    print(f'Headline R2: {headline_r2}')\n",
    "    print(f'R2 list percentiles:\\n[10: {np.percentile(r_squared_lst, 10)}, 25: {np.percentile(r_squared_lst, 25)}, 50: {np.percentile(r_squared_lst, 50)}, 75: {np.percentile(r_squared_lst, 75)}, 90: {np.percentile(r_squared_lst, 90)}]')\n",
    "\n",
    "    return headline_r2, avg_r2_score\n",
    "\n",
    "headline_r2, avg_r2_score = avg_r_squared(all_data_test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(all_data_dict, categories):\n",
    "    category_samples = ['All items']+random.sample(categories, 10)\n",
    "    for category in category_samples:\n",
    "        category_df = all_data_dict[category]\n",
    "        fig = px.line(category_df, x=\"Date\", y=[\"Actual\", \"Prediction\"], title=f'{category} - Actual VS Prediction')\n",
    "        fig.show()\n",
    "\n",
    "plot_results(all_data_test_dict, all_categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
