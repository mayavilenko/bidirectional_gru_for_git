{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "from pickle_file_config import *\n",
    "from previous_utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Test:\n",
    "us_bi_directional_path = US_HRNN_PATH\n",
    "\n",
    "us_bi_directional_data=preprocess_data(us_bi_directional_path, 12, 1)\n",
    "us_bi_directional_data.columns = columns_order\n",
    "us_bi_directional_data.sort_values(['Category','Category_id','Date'], inplace = True)\n",
    "us_bi_directional_dataset_dict = {}\n",
    "\n",
    "for category in list(us_bi_directional_data['Category'].unique()):\n",
    "    us_bi_directional_dataset_dict[category] = us_bi_directional_data[us_bi_directional_data['Category'] == category]\n",
    "    \n",
    "with open(US_bi_directional_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(us_bi_directional_dataset_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Test:\n",
    "us_bi_directional_dataset_dict['All items']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating US's (1) Son-Parent Dict, (2) Category ID to Name Dict, (3) Categories per Indent Dict, (4) Parent to Sons List Dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_parent_dict = {}\n",
    "us_weight_dict = {}\n",
    "us_cat_cat_id_dict = {}\n",
    "us_indent_dict = {}\n",
    "us_parent_to_sons_dict = {}\n",
    "\n",
    "us_parent_df = us_bi_directional_data[['Category_id', 'Parent_ID']].drop_duplicates()\n",
    "us_cat_weight_df = us_bi_directional_data[['Category_id','Weight']].drop_duplicates()\n",
    "us_cat_cat_id_df = us_bi_directional_data[['Category_id','Category']].drop_duplicates()\n",
    "us_indent_df = us_bi_directional_data[['Indent','Category_id']].drop_duplicates()\n",
    "\n",
    "for category_id in list(us_parent_df['Category_id'].unique()):\n",
    "    us_parent_dict[category_id] = us_parent_df[us_parent_df['Category_id'] == category_id]['Parent_ID'].values[0]\n",
    "    \n",
    "for category_id in list(us_cat_weight_df['Category_id'].unique()):\n",
    "    us_weight_dict[category_id] = us_cat_weight_df[us_cat_weight_df['Category_id'] == category_id]['Weight'].values[0]\n",
    "    \n",
    "for category_id in list(us_cat_cat_id_df['Category_id'].unique()):\n",
    "    us_cat_cat_id_dict[category_id] = us_cat_cat_id_df[us_cat_cat_id_df['Category_id'] == category_id]['Category'].values[0]\n",
    "    \n",
    "for indent in list(us_indent_df['Indent'].unique()):\n",
    "    us_indent_dict[indent] = list(us_indent_df[us_indent_df['Indent']==indent].Category_id.unique())\n",
    "\n",
    "for cat_id in list(us_bi_directional_data.Category_id.unique()):\n",
    "    if us_parent_dict[cat_id] in list(us_parent_to_sons_dict.keys()):\n",
    "        us_parent_to_sons_dict[us_parent_dict[cat_id]]['sons'].append(cat_id)\n",
    "    \n",
    "    else:\n",
    "        us_parent_to_sons_dict[us_parent_dict[cat_id]] = {'sons': [cat_id]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(us_parent_son_pickle, 'wb') as handle: \n",
    "    pickle.dump(us_parent_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(us_cat_weight_pickle, 'wb') as handle: \n",
    "    pickle.dump(us_weight_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(us_category_id_to_name_pickle, 'wb') as handle: \n",
    "    pickle.dump(us_cat_cat_id_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(us_category_id_per_indent_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(us_indent_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(us_parent_to_sons_list_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(us_parent_to_sons_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print categories with no parents - making sure the only category without parent id is all items (8106)\n",
    "for cat_id in list(us_parent_dict.keys()):\n",
    "    if pd.isna(us_parent_dict[cat_id]):\n",
    "        print(cat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Parent Son Name Dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(us_category_id_to_name_pickle, 'rb') as f:\n",
    "    category_id_to_name_dict = pickle.load(f)\n",
    "\n",
    "with open(us_parent_son_pickle, 'rb') as f:\n",
    "    son_parent_dict = pickle.load(f)\n",
    "\n",
    "parent_son_name_dict = {}\n",
    "\n",
    "for son_id in list(category_id_to_name_dict.keys()):\n",
    "    son_id = int(son_id)\n",
    "    son_name = category_id_to_name_dict[son_id]\n",
    "    if son_name == 'All items':\n",
    "        parent_son_name_dict[son_name] = None\n",
    "    else:\n",
    "        parent_id = int(son_parent_dict[son_id])\n",
    "        if parent_id in list(category_id_to_name_dict.keys()):\n",
    "            parent_name = category_id_to_name_dict[parent_id]\n",
    "            parent_son_name_dict[son_name] = parent_name\n",
    "\n",
    "with open(us_parent_son_name_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(parent_son_name_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Canada Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Test:\n",
    "canada_bi_directional_path = CANADA_HRNN_PATH\n",
    "\n",
    "canada_bi_directional_data=preprocess_data(canada_bi_directional_path, 12, 1)\n",
    "canada_bi_directional_data.columns = columns_order\n",
    "canada_bi_directional_data.sort_values(['Category','Category_id','Date'], inplace = True)\n",
    "canada_bi_directional_dataset_dict = {}\n",
    "\n",
    "for category in list(canada_bi_directional_data['Category'].unique()):\n",
    "    canada_bi_directional_dataset_dict[category] = canada_bi_directional_data[canada_bi_directional_data['Category'] == category]\n",
    "    \n",
    "with open(canada_bi_directional_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(canada_bi_directional_dataset_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Test:\n",
    "canada_bi_directional_dataset_dict['All-items']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Canada's (1) Son-Parent Dict, (2) Category ID to Name Dict, (3) Categories per Indent Dict, (4) Parent to Sons List Dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_parent_dict = {}\n",
    "canada_weight_dict = {}\n",
    "canada_cat_cat_id_dict = {}\n",
    "canada_indent_dict = {}\n",
    "canada_parent_to_sons_dict = {}\n",
    "\n",
    "canada_parent_df = canada_bi_directional_data[['Category_id', 'Parent_ID']].drop_duplicates()\n",
    "canada_cat_weight_df = canada_bi_directional_data[['Category_id','Weight']].drop_duplicates()\n",
    "canada_cat_cat_id_df = canada_bi_directional_data[['Category_id','Category']].drop_duplicates()\n",
    "canada_indent_df = canada_bi_directional_data[['Indent','Category_id']].drop_duplicates()\n",
    "\n",
    "for category_id in list(canada_parent_df['Category_id'].unique()):\n",
    "    canada_parent_dict[category_id] = canada_parent_df[canada_parent_df['Category_id'] == category_id]['Parent_ID'].values[0]\n",
    "    \n",
    "for category_id in list(canada_cat_weight_df['Category_id'].unique()):\n",
    "    canada_weight_dict[category_id] = canada_cat_weight_df[canada_cat_weight_df['Category_id'] == category_id]['Weight'].values[0]\n",
    "    \n",
    "for category_id in list(canada_cat_cat_id_df['Category_id'].unique()):\n",
    "    canada_cat_cat_id_dict[category_id] = canada_cat_cat_id_df[canada_cat_cat_id_df['Category_id'] == category_id]['Category'].values[0]\n",
    "    \n",
    "for indent in list(canada_indent_df['Indent'].unique()):\n",
    "    canada_indent_dict[indent] = list(canada_indent_df[canada_indent_df['Indent']==indent].Category_id.unique())\n",
    "\n",
    "for cat_id in list(canada_bi_directional_data.Category_id.unique()):\n",
    "    if canada_parent_dict[cat_id] in list(canada_parent_to_sons_dict.keys()):\n",
    "        canada_parent_to_sons_dict[canada_parent_dict[cat_id]]['sons'].append(cat_id)\n",
    "    \n",
    "    else:\n",
    "        canada_parent_to_sons_dict[canada_parent_dict[cat_id]] = {'sons': [cat_id]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(canada_parent_son_pickle, 'wb') as handle: \n",
    "    pickle.dump(canada_parent_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(canada_cat_weight_pickle, 'wb') as handle: \n",
    "    pickle.dump(canada_weight_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(canada_category_id_to_name_pickle, 'wb') as handle: \n",
    "    pickle.dump(canada_cat_cat_id_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(canada_category_id_per_indent_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(canada_indent_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(canada_parent_to_sons_list_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(canada_parent_to_sons_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print categories with no parents - making sure the only category without parent id is all items (2)\n",
    "for cat_id in list(canada_parent_dict.keys()):\n",
    "    if pd.isna(canada_parent_dict[cat_id]):\n",
    "        print(cat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Parent Son Name Dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(canada_category_id_to_name_pickle, 'rb') as f:\n",
    "    category_id_to_name_dict = pickle.load(f)\n",
    "\n",
    "with open(canada_parent_son_pickle, 'rb') as f:\n",
    "    son_parent_dict = pickle.load(f)\n",
    "\n",
    "parent_son_name_dict = {}\n",
    "\n",
    "for son_id in list(category_id_to_name_dict.keys()):\n",
    "    son_id = int(son_id)\n",
    "    son_name = category_id_to_name_dict[son_id]\n",
    "    if son_name == 'All-items':\n",
    "        parent_son_name_dict[son_name] = None\n",
    "    else:\n",
    "        parent_id = int(son_parent_dict[son_id])\n",
    "        if parent_id in list(category_id_to_name_dict.keys()):\n",
    "            parent_name = category_id_to_name_dict[parent_id]\n",
    "            parent_son_name_dict[son_name] = parent_name\n",
    "\n",
    "with open(canada_parent_son_name_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(parent_son_name_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norway Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Test:\n",
    "norway_bi_directional_path = NORWAY_HRNN_PATH\n",
    "\n",
    "norway_bi_directional_data=preprocess_data(norway_bi_directional_path, 12, 1)\n",
    "norway_bi_directional_data.columns = columns_order\n",
    "norway_bi_directional_data.sort_values(['Category','Category_id','Date'], inplace = True)\n",
    "norway_bi_directional_dataset_dict = {}\n",
    "\n",
    "for category in list(norway_bi_directional_data['Category'].unique()):\n",
    "    norway_bi_directional_dataset_dict[category] = norway_bi_directional_data[norway_bi_directional_data['Category'] == category]\n",
    "    \n",
    "with open(norway_bi_directional_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(norway_bi_directional_dataset_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Test:\n",
    "norway_bi_directional_dataset_dict['All-items']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Norway's (1) Son-Parent Dict, (2) Category ID to Name Dict, (3) Categories per Indent Dict, (4) Parent to Sons List Dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norway_parent_dict = {}\n",
    "norway_weight_dict = {}\n",
    "norway_cat_cat_id_dict = {}\n",
    "norway_indent_dict = {}\n",
    "norway_parent_to_sons_dict = {}\n",
    "\n",
    "norway_parent_df = norway_bi_directional_data[['Category_id', 'Parent_ID']].drop_duplicates()\n",
    "norway_cat_weight_df = norway_bi_directional_data[['Category_id','Weight']].drop_duplicates()\n",
    "norway_cat_cat_id_df = norway_bi_directional_data[['Category_id','Category']].drop_duplicates()\n",
    "norway_indent_df = norway_bi_directional_data[['Indent','Category_id']].drop_duplicates()\n",
    "\n",
    "for category_id in list(norway_parent_df['Category_id'].unique()):\n",
    "    norway_parent_dict[category_id] = norway_parent_df[norway_parent_df['Category_id'] == category_id]['Parent_ID'].values[0]\n",
    "    \n",
    "for category_id in list(norway_cat_weight_df['Category_id'].unique()):\n",
    "    norway_weight_dict[category_id] = norway_cat_weight_df[norway_cat_weight_df['Category_id'] == category_id]['Weight'].values[0]\n",
    "    \n",
    "for category_id in list(norway_cat_cat_id_df['Category_id'].unique()):\n",
    "    norway_cat_cat_id_dict[category_id] = norway_cat_cat_id_df[norway_cat_cat_id_df['Category_id'] == category_id]['Category'].values[0]\n",
    "    \n",
    "for indent in list(norway_indent_df['Indent'].unique()):\n",
    "    norway_indent_dict[indent] = list(norway_indent_df[norway_indent_df['Indent']==indent].Category_id.unique())\n",
    "\n",
    "for cat_id in list(norway_bi_directional_data.Category_id.unique()):\n",
    "    if norway_parent_dict[cat_id] in list(norway_parent_to_sons_dict.keys()):\n",
    "        norway_parent_to_sons_dict[norway_parent_dict[cat_id]]['sons'].append(cat_id)\n",
    "    \n",
    "    else:\n",
    "        norway_parent_to_sons_dict[norway_parent_dict[cat_id]] = {'sons': [cat_id]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(norway_parent_son_pickle, 'wb') as handle: \n",
    "    pickle.dump(norway_parent_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(norway_cat_weight_pickle, 'wb') as handle: \n",
    "    pickle.dump(norway_weight_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(norway_category_id_to_name_pickle, 'wb') as handle: \n",
    "    pickle.dump(norway_cat_cat_id_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(norway_category_id_per_indent_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(norway_indent_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(norway_parent_to_sons_list_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(norway_parent_to_sons_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print categories with no parents - making sure the only category without parent id is all items (0)\n",
    "for cat_id in list(norway_parent_dict.keys()):\n",
    "    if pd.isna(norway_parent_dict[cat_id]):\n",
    "        print(cat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Parent Son Name Dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(norway_category_id_to_name_pickle, 'rb') as f:\n",
    "    category_id_to_name_dict = pickle.load(f)\n",
    "\n",
    "with open(norway_parent_son_pickle, 'rb') as f:\n",
    "    son_parent_dict = pickle.load(f)\n",
    "\n",
    "parent_son_name_dict = {}\n",
    "\n",
    "for son_id in list(category_id_to_name_dict.keys()):\n",
    "    son_id = int(son_id)\n",
    "    son_name = category_id_to_name_dict[son_id]\n",
    "    if son_name == 'All-items':\n",
    "        parent_son_name_dict[son_name] = None\n",
    "    else:\n",
    "        parent_id = int(son_parent_dict[son_id])\n",
    "        if parent_id in list(category_id_to_name_dict.keys()):\n",
    "            parent_name = category_id_to_name_dict[parent_id]\n",
    "            parent_son_name_dict[son_name] = parent_name\n",
    "\n",
    "with open(norway_parent_son_name_pickle, 'wb') as handle: #wb means write - creating a pickle file\n",
    "    pickle.dump(parent_son_name_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
