{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import statistics\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from transformers import AdamW\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import shutil\n",
    "\n",
    "from GRU_model import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeds for Comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(2)\n",
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/mvilenko/Desktop/CPI_HRNN - version 2.0/mayas_project/SGRU/data/train_dataset.pickle', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "    \n",
    "with open('/Users/mvilenko/Desktop/CPI_HRNN - version 2.0/mayas_project/SGRU/data/test_dataset.pickle', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17828, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inflation t-12</th>\n",
       "      <th>Inflation t-11</th>\n",
       "      <th>Inflation t-10</th>\n",
       "      <th>Inflation t-9</th>\n",
       "      <th>Inflation t-8</th>\n",
       "      <th>Inflation t-7</th>\n",
       "      <th>Inflation t-6</th>\n",
       "      <th>Inflation t-5</th>\n",
       "      <th>Inflation t-4</th>\n",
       "      <th>Inflation t-3</th>\n",
       "      <th>Inflation t-2</th>\n",
       "      <th>Inflation t-1</th>\n",
       "      <th>Inflation t</th>\n",
       "      <th>Inflation t+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51379</th>\n",
       "      <td>0.346759</td>\n",
       "      <td>0.122860</td>\n",
       "      <td>-0.287493</td>\n",
       "      <td>-0.254331</td>\n",
       "      <td>-0.265488</td>\n",
       "      <td>0.124384</td>\n",
       "      <td>0.387922</td>\n",
       "      <td>0.256546</td>\n",
       "      <td>0.419889</td>\n",
       "      <td>-0.161491</td>\n",
       "      <td>-0.142182</td>\n",
       "      <td>0.241591</td>\n",
       "      <td>-0.007559</td>\n",
       "      <td>0.307399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51380</th>\n",
       "      <td>0.307399</td>\n",
       "      <td>0.346759</td>\n",
       "      <td>0.122860</td>\n",
       "      <td>-0.287493</td>\n",
       "      <td>-0.254331</td>\n",
       "      <td>-0.265488</td>\n",
       "      <td>0.124384</td>\n",
       "      <td>0.387922</td>\n",
       "      <td>0.256546</td>\n",
       "      <td>0.419889</td>\n",
       "      <td>-0.161491</td>\n",
       "      <td>-0.142182</td>\n",
       "      <td>0.241591</td>\n",
       "      <td>0.461293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51381</th>\n",
       "      <td>0.461293</td>\n",
       "      <td>0.307399</td>\n",
       "      <td>0.346759</td>\n",
       "      <td>0.122860</td>\n",
       "      <td>-0.287493</td>\n",
       "      <td>-0.254331</td>\n",
       "      <td>-0.265488</td>\n",
       "      <td>0.124384</td>\n",
       "      <td>0.387922</td>\n",
       "      <td>0.256546</td>\n",
       "      <td>0.419889</td>\n",
       "      <td>-0.161491</td>\n",
       "      <td>-0.142182</td>\n",
       "      <td>0.266383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51382</th>\n",
       "      <td>0.266383</td>\n",
       "      <td>0.461293</td>\n",
       "      <td>0.307399</td>\n",
       "      <td>0.346759</td>\n",
       "      <td>0.122860</td>\n",
       "      <td>-0.287493</td>\n",
       "      <td>-0.254331</td>\n",
       "      <td>-0.265488</td>\n",
       "      <td>0.124384</td>\n",
       "      <td>0.387922</td>\n",
       "      <td>0.256546</td>\n",
       "      <td>0.419889</td>\n",
       "      <td>-0.161491</td>\n",
       "      <td>0.757317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51383</th>\n",
       "      <td>0.757317</td>\n",
       "      <td>0.266383</td>\n",
       "      <td>0.461293</td>\n",
       "      <td>0.307399</td>\n",
       "      <td>0.346759</td>\n",
       "      <td>0.122860</td>\n",
       "      <td>-0.287493</td>\n",
       "      <td>-0.254331</td>\n",
       "      <td>-0.265488</td>\n",
       "      <td>0.124384</td>\n",
       "      <td>0.387922</td>\n",
       "      <td>0.256546</td>\n",
       "      <td>0.419889</td>\n",
       "      <td>0.157281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37173</th>\n",
       "      <td>-0.132909</td>\n",
       "      <td>0.176656</td>\n",
       "      <td>1.067445</td>\n",
       "      <td>-0.762470</td>\n",
       "      <td>-0.225467</td>\n",
       "      <td>-0.130396</td>\n",
       "      <td>0.258277</td>\n",
       "      <td>0.408885</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.956554</td>\n",
       "      <td>0.263887</td>\n",
       "      <td>0.526196</td>\n",
       "      <td>0.282573</td>\n",
       "      <td>0.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37174</th>\n",
       "      <td>0.484400</td>\n",
       "      <td>-0.132909</td>\n",
       "      <td>0.176656</td>\n",
       "      <td>1.067445</td>\n",
       "      <td>-0.762470</td>\n",
       "      <td>-0.225467</td>\n",
       "      <td>-0.130396</td>\n",
       "      <td>0.258277</td>\n",
       "      <td>0.408885</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.956554</td>\n",
       "      <td>0.263887</td>\n",
       "      <td>0.526196</td>\n",
       "      <td>0.820072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37175</th>\n",
       "      <td>0.820072</td>\n",
       "      <td>0.484400</td>\n",
       "      <td>-0.132909</td>\n",
       "      <td>0.176656</td>\n",
       "      <td>1.067445</td>\n",
       "      <td>-0.762470</td>\n",
       "      <td>-0.225467</td>\n",
       "      <td>-0.130396</td>\n",
       "      <td>0.258277</td>\n",
       "      <td>0.408885</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.956554</td>\n",
       "      <td>0.263887</td>\n",
       "      <td>0.019381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37176</th>\n",
       "      <td>0.019381</td>\n",
       "      <td>0.820072</td>\n",
       "      <td>0.484400</td>\n",
       "      <td>-0.132909</td>\n",
       "      <td>0.176656</td>\n",
       "      <td>1.067445</td>\n",
       "      <td>-0.762470</td>\n",
       "      <td>-0.225467</td>\n",
       "      <td>-0.130396</td>\n",
       "      <td>0.258277</td>\n",
       "      <td>0.408885</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.956554</td>\n",
       "      <td>-0.651313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37177</th>\n",
       "      <td>-0.651313</td>\n",
       "      <td>0.019381</td>\n",
       "      <td>0.820072</td>\n",
       "      <td>0.484400</td>\n",
       "      <td>-0.132909</td>\n",
       "      <td>0.176656</td>\n",
       "      <td>1.067445</td>\n",
       "      <td>-0.762470</td>\n",
       "      <td>-0.225467</td>\n",
       "      <td>-0.130396</td>\n",
       "      <td>0.258277</td>\n",
       "      <td>0.408885</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>-0.544980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2356 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Inflation t-12  Inflation t-11  Inflation t-10  Inflation t-9  \\\n",
       "51379        0.346759        0.122860       -0.287493      -0.254331   \n",
       "51380        0.307399        0.346759        0.122860      -0.287493   \n",
       "51381        0.461293        0.307399        0.346759       0.122860   \n",
       "51382        0.266383        0.461293        0.307399       0.346759   \n",
       "51383        0.757317        0.266383        0.461293       0.307399   \n",
       "...               ...             ...             ...            ...   \n",
       "37173       -0.132909        0.176656        1.067445      -0.762470   \n",
       "37174        0.484400       -0.132909        0.176656       1.067445   \n",
       "37175        0.820072        0.484400       -0.132909       0.176656   \n",
       "37176        0.019381        0.820072        0.484400      -0.132909   \n",
       "37177       -0.651313        0.019381        0.820072       0.484400   \n",
       "\n",
       "       Inflation t-8  Inflation t-7  Inflation t-6  Inflation t-5  \\\n",
       "51379      -0.265488       0.124384       0.387922       0.256546   \n",
       "51380      -0.254331      -0.265488       0.124384       0.387922   \n",
       "51381      -0.287493      -0.254331      -0.265488       0.124384   \n",
       "51382       0.122860      -0.287493      -0.254331      -0.265488   \n",
       "51383       0.346759       0.122860      -0.287493      -0.254331   \n",
       "...              ...            ...            ...            ...   \n",
       "37173      -0.225467      -0.130396       0.258277       0.408885   \n",
       "37174      -0.762470      -0.225467      -0.130396       0.258277   \n",
       "37175       1.067445      -0.762470      -0.225467      -0.130396   \n",
       "37176       0.176656       1.067445      -0.762470      -0.225467   \n",
       "37177      -0.132909       0.176656       1.067445      -0.762470   \n",
       "\n",
       "       Inflation t-4  Inflation t-3  Inflation t-2  Inflation t-1  \\\n",
       "51379       0.419889      -0.161491      -0.142182       0.241591   \n",
       "51380       0.256546       0.419889      -0.161491      -0.142182   \n",
       "51381       0.387922       0.256546       0.419889      -0.161491   \n",
       "51382       0.124384       0.387922       0.256546       0.419889   \n",
       "51383      -0.265488       0.124384       0.387922       0.256546   \n",
       "...              ...            ...            ...            ...   \n",
       "37173       0.522500       0.956554       0.263887       0.526196   \n",
       "37174       0.408885       0.522500       0.956554       0.263887   \n",
       "37175       0.258277       0.408885       0.522500       0.956554   \n",
       "37176      -0.130396       0.258277       0.408885       0.522500   \n",
       "37177      -0.225467      -0.130396       0.258277       0.408885   \n",
       "\n",
       "       Inflation t  Inflation t+1  \n",
       "51379    -0.007559       0.307399  \n",
       "51380     0.241591       0.461293  \n",
       "51381    -0.142182       0.266383  \n",
       "51382    -0.161491       0.757317  \n",
       "51383     0.419889       0.157281  \n",
       "...            ...            ...  \n",
       "37173     0.282573       0.484400  \n",
       "37174     0.526196       0.820072  \n",
       "37175     0.263887       0.019381  \n",
       "37176     0.956554      -0.651313  \n",
       "37177     0.522500      -0.544980  \n",
       "\n",
       "[2356 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(category_train_df, category_test_df):\n",
    "    x_train = category_train_df.iloc[:,:-1].to_numpy()\n",
    "    y_train = category_train_df.iloc[:,-1].to_numpy()\n",
    "    x_test = category_test_df.iloc[:,:-1].to_numpy()\n",
    "    y_test= category_test_df.iloc[:,-1].to_numpy()\n",
    "\n",
    "    x_train= torch.from_numpy(x_train).to(torch.float32)\n",
    "    y_train = torch.from_numpy(y_train).to(torch.float32)\n",
    "    x_test = torch.from_numpy(x_test).to(torch.float32)\n",
    "    y_test = torch.from_numpy(y_test).to(torch.float32)\n",
    "\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    test_dataset = TensorDataset(x_test, y_test)\n",
    "    train_dataloader =  DataLoader(train_dataset, batch_size=BatchSize, shuffle=False)\n",
    "    test_dataloader =  DataLoader(test_dataset, batch_size=BatchSize, shuffle=False)\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_dataloader, optimizer):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    predictions_list = []\n",
    "    for inputs, labels in train_dataloader:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #Changing input shape - last batch size can change so we define it as input.shape[0]\n",
    "        inputs = inputs.view(inputs.shape[0], SequenceLength, Features) \n",
    "        #model prediction\n",
    "        pred = model(inputs)\n",
    "        #append batch predictions to predictions list\n",
    "        predictions_list.append(pred.view(1,-1))\n",
    "        # calculate loss\n",
    "        loss = Criterion(pred, labels.view(-1,1))\n",
    "        # calculate the gradient\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        #Add to loss of batch to epoch train loss\n",
    "        running_loss+=loss.item()\n",
    "    # Calculte the epoch train loss\n",
    "    epoch_train_loss = running_loss/len(train_dataloader.dataset)\n",
    "    return epoch_train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_loop(model, test_dataloader):\n",
    "     # Evaluation\n",
    "    # Initiate test loss, accuracy and f1 score to zero\n",
    "    test_loss = 0\n",
    "    # Change model to eval mode\n",
    "    model.eval()\n",
    "    # we dont need to update weights, so we define no_grad() to save memory\n",
    "\n",
    "    predictions_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.view(inputs.shape[0], SequenceLength, Features)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            out = model(inputs)\n",
    "            predictions_list.append(out.view(1,-1))\n",
    "            test_batch_loss = Criterion(out, labels.view(-1,1))\n",
    "            test_loss += test_batch_loss.item()\n",
    "    # Calculate epoch loss\n",
    "    epoch_predictions = torch.cat(predictions_list, dim=1)\n",
    "    epoch_test_loss = test_loss/len(test_dataloader.dataset)\n",
    "        \n",
    "    return epoch_test_loss, epoch_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    checkpoint: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(checkpoint_path, best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_and_evaluation(model, train_dataloader, test_dataloader, optim, checkpoint_path, best_checkpoint_path):\n",
    "   #results list\n",
    "   train_loss_list = []\n",
    "   test_loss_list = []\n",
    "\n",
    "   #Create writer for using tesndorboard\n",
    "   writer = SummaryWriter(log_dir=f'{TbDirectory}')\n",
    "\n",
    "   min_test_loss = np.inf\n",
    "\n",
    "   for epoch in range(Epochs):\n",
    "      #initiate train epoch loss\n",
    "      epoch_train_loss = training_loop(model, train_dataloader, optim)\n",
    "      epoch_test_loss, epoch_test_predictions = evaluation_loop(model, test_dataloader)\n",
    "\n",
    "      checkpoint = {\n",
    "         'epoch': epoch + 1,\n",
    "         'valid_loss_min': epoch_test_loss,\n",
    "         'state_dict': model.state_dict(),\n",
    "         'optimizer': optim.state_dict(),\n",
    "        }\n",
    "      \n",
    "      # save checkpoint\n",
    "      save_checkpoint(checkpoint, False, checkpoint_path, best_checkpoint_path)\n",
    "\n",
    "      if epoch_test_loss <= min_test_loss:\n",
    "         save_checkpoint(checkpoint, True, checkpoint_path, best_checkpoint_path)\n",
    "         min_test_loss = epoch_test_loss\n",
    "\n",
    "      train_loss_list.append(epoch_train_loss)\n",
    "      test_loss_list.append(epoch_test_loss)\n",
    "\n",
    "      # Display those measures on tensorboard\n",
    "      writer.add_scalar(tag='loss/train', scalar_value=epoch_train_loss, global_step=epoch)\n",
    "      writer.add_scalar(tag='loss/test', scalar_value=epoch_test_loss, global_step=epoch)\n",
    "    \n",
    "   results = {'train_loss': train_loss_list, 'test_loss': test_loss_list}\n",
    "   return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipline(train_dataset, test_dataset):\n",
    "    train_dataloader, test_dataloader = create_dataloader(train_dataset, test_dataset)\n",
    "\n",
    "    model = GRUModel(input_dim = Features, hidden_dim = HiddenSize, layer_dim = LayersDim, output_dim = OutputDim, dropout_prob = DropoutProb)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=Lr)\n",
    "\n",
    "    parameters_file_name = 'single_gru_params.pt'\n",
    "    \n",
    "    results = training_and_evaluation(\n",
    "                            model=model,\n",
    "                            optim=optimizer,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            test_dataloader=test_dataloader,\n",
    "                            checkpoint_path=CheckpointPath+parameters_file_name,\n",
    "                            best_checkpoint_path=BestcheckpointPath+parameters_file_name,\n",
    "                        )\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipline(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/mvilenko/Desktop/CPI_HRNN - version 2.0/mayas_project/SGRU/data/model_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_best_model(dir_path):\n",
    "    basic_model = GRUModel(input_dim = Features, hidden_dim = HiddenSize, layer_dim = LayersDim, output_dim = OutputDim, dropout_prob = DropoutProb)\n",
    "    basic_optimizer = torch.optim.AdamW(basic_model.parameters(), lr=Lr)\n",
    "    basic_model.to(device)\n",
    "\n",
    "    ckp_path = dir_path+'single_gru_params.pt'\n",
    "    best_model, optimizer, checkpoint, valid_loss_min = load_checkpoint(ckp_path, basic_model, basic_optimizer)\n",
    "        \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"checkpoints/best_checkpoints/\"\n",
    "\n",
    "best_model = create_best_model(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUModel(\n",
       "  (gru): GRU(1, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Best Predictions for Each Category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_predictions(best_model):\n",
    "    train_dataloader, test_dataloader = create_dataloader(train_dataset, test_dataset)\n",
    "    epoch_test_loss, epoch_predictions = evaluation_loop(best_model, test_dataloader)\n",
    "    best_predictions = epoch_predictions\n",
    "\n",
    "    return best_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictions = get_best_predictions(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/mvilenko/Desktop/CPI_HRNN - version 2.0/mayas_project/SGRU/data/predictions.pickle', 'wb') as handle:\n",
    "    pickle.dump(best_predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (v3.10.8:aaaf517424, Oct 11 2022, 10:14:40) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
